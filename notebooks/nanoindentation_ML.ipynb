   "source": "## Importing the indentation dataset\nLoad the raw nanoindentation map from a CSV file. After loading we reorder the columns and remove invalid hardness values."
   "source": "## Cleaning the data\nOutliers are detected with an interquartile range filter and removed. The distribution before and after cleaning is displayed."
   "source": "## Exploring the measurement data\nA scatter matrix with histograms reveals correlations such as hardness versus modulus."
   "source": "## Visualizing spatial maps\nHere we plot spatial maps of modulus and hardness together with a density plot."
    "ax[0].set_xlabel('X Position (\u03bcm)')\n",
    "ax[0].set_ylabel('Y Position (\u03bcm)')\n",
    "ax[1].set_xlabel('X Position (\u03bcm)')\n",
    "ax[1].set_ylabel('Y Position (\u03bcm)')\n",
   "source": "## Normalizing the dataset\nThe variables are centered and scaled so they are on comparable ranges."
   "source": "## Principal component analysis\nPCA reduces the dimensionality of the normalized data for visualization and clustering."
   "source": "## Clustering with DBSCAN\nWe apply DBSCAN to find dense clusters without specifying their number in advance."
   "source": "## Clustering with Gaussian mixture models\nGaussian mixture models estimate overlapping clusters in the data."
   "source": "## Clustering with k-means\nK-means partitions the observations into a fixed number of clusters using Euclidean distance."
   "source": "## Computing cluster statistics\nFor each cluster we compute the average modulus and hardness along with their standard deviation."
   "source": "## Visualizing cluster maps\nThe spatial distribution of each cluster is displayed for interpretation."
      "\u001b[0;32m<ipython-input-53-8b96e1675edf>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mcluster_grid_individual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_grid_individual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X Position (\u03bcm)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
    "axes[0, 0].set_xlabel('X Position (\u03bcm)')\n",
    "axes[0, 0].set_ylabel('Y Position (\u03bcm)')\n",
    "    ax.set_xlabel('X Position (\u03bcm)')\n",
    "    ax.set_ylabel('Y Position (\u03bcm)')\n",
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Comparing clustering methods\nThis section runs DBSCAN, k-means, k-medoids and GMM on the same features, shows the resulting clusters side by side and prints summary statistics."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np",
    "import pandas as pd",
    "import matplotlib.pyplot as plt",
    "from sklearn.cluster import DBSCAN, KMeans",
    "from sklearn.mixture import GaussianMixture",
    "from sklearn.metrics import pairwise_distances",
    "from sklearn.decomposition import PCA",
    "",
    "def k_medoids(X, n_clusters, max_iter=300):",
    "    m = X.shape[0]",
    "    medoid_indices = np.random.choice(m, n_clusters, replace=False)",
    "    labels = np.zeros(m, dtype=int)",
    "    for _ in range(max_iter):",
    "        medoids = X[medoid_indices]",
    "        dist = pairwise_distances(X, medoids)",
    "        labels = dist.argmin(axis=1)",
    "        new_medoids = medoid_indices.copy()",
    "        for i in range(n_clusters):",
    "            idx = np.where(labels == i)[0]",
    "            if len(idx) == 0:",
    "                continue",
    "            sub_dist = pairwise_distances(X[idx])",
    "            costs = sub_dist.sum(axis=1)",
    "            new_medoids[i] = idx[costs.argmin()]",
    "        if np.all(new_medoids == medoid_indices):",
    "            break",
    "        medoid_indices = new_medoids",
    "    return labels",
    "",
    "X = np.column_stack((nData['MODULUS'], nData['HARDNESS']))",
    "",
    "db_labels = DBSCAN(eps=0.5, min_samples=10).fit_predict(X)",
    "km_labels = KMeans(n_clusters=4, n_init=10, random_state=1).fit_predict(X)",
    "kmid_labels = k_medoids(X, n_clusters=4)",
    "gmm_labels = GaussianMixture(n_components=4, covariance_type='full', random_state=1).fit_predict(X)",
    "",
    "methods = {'DBSCAN': db_labels, 'KMeans': km_labels, 'KMedoids': kmid_labels, 'GMM': gmm_labels}",
    "",
    "pca_vis = PCA(n_components=2).fit_transform(X)",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))",
    "for ax, (name, lbls) in zip(axes.ravel(), methods.items()):",
    "    ax.scatter(pca_vis[:, 0], pca_vis[:, 1], c=lbls, cmap='tab10', s=3)",
    "    ax.set_title(name)",
    "    ax.set_xlabel('PC1')",
    "    ax.set_ylabel('PC2')",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "def stats(labels):",
    "    df = filteredData.copy()",
    "    df['cluster'] = labels",
    "    return df.groupby('cluster')[['MODULUS', 'HARDNESS']].agg(['mean', 'std'])",
    "",
    "summary = pd.concat({name: stats(lbls) for name, lbls in methods.items()}, axis=1)",
    "summary"
   ]
}