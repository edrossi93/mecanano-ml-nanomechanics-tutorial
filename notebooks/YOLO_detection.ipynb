{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Severstal Steel Defect Dataset Downloader\n",
    "\n",
    "This notebook guides you through:\n",
    "1. Setting up the Kaggle API\n",
    "2. Downloading the Severstal Steel Defect Detection dataset\n",
    "3. Unzipping the dataset and image files\n",
    "\n",
    "‚ö†Ô∏è **Important**: You must have a [Kaggle](https://www.kaggle.com) account and an API token (`kaggle.json`) to use this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ‚úÖ Install Kaggle CLI if not already installed\n",
    "# ============================================\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üîë Upload your Kaggle API key\n",
    "# ============================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle_dir = Path.home() / \".kaggle\"\n",
    "kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import FileUpload\n",
    "\n",
    "upload_widget = FileUpload(accept='.json', multiple=False)\n",
    "display(upload_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the uploaded file to ~/.kaggle/kaggle.json\n",
    "for name, file_info in upload_widget.value.items():\n",
    "    kaggle_json_path = kaggle_dir / \"kaggle.json\"\n",
    "    kaggle_json_path.write_bytes(file_info[\"content\"])\n",
    "    os.chmod(kaggle_json_path, 0o600)\n",
    "    print(f\"Kaggle API key saved to {kaggle_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ‚¨áÔ∏è Download the Severstal dataset ZIP file\n",
    "# ============================================\n",
    "!kaggle competitions download -c severstal-steel-defect-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üóÇÔ∏è Unzip main dataset archive\n",
    "# ============================================\n",
    "import zipfile\n",
    "\n",
    "main_zip = \"severstal-steel-defect-detection.zip\"\n",
    "extract_path = Path(\"severstal_dataset\")\n",
    "extract_path.mkdir(exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(main_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Extracted dataset contents to:\", extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üñºÔ∏è Unzip train/test image folders\n",
    "# ============================================\n",
    "for zip_name in [\"train_images.zip\", \"test_images.zip\"]:\n",
    "    zip_path = extract_path / zip_name\n",
    "    if zip_path.exists():\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            target_dir = extract_path / zip_name.replace(\".zip\", \"\")\n",
    "            target_dir.mkdir(exist_ok=True)\n",
    "            zip_ref.extractall(target_dir)\n",
    "            print(f\"Extracted {zip_name} to {target_dir}\")\n",
    "    else:\n",
    "        print(f\"{zip_name} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Download Complete\n",
    "\n",
    "You now have:\n",
    "- `train.csv`: CSV file with encoded mask annotations\n",
    "- `train_images/`: directory with ~12,000 training SEM-like images\n",
    "- `test_images/`: directory with test images\n",
    "- `sample_submission.csv`: template for prediction format\n",
    "\n",
    "Next step: parse the annotations and visualize defects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Visualize Sample Defect Annotations\n",
    "\n",
    "This cell loads a few random images from the training set and overlays defect masks based on the `train.csv` annotations. \n",
    "This helps explore what the defect labels look like, and how masks are encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Load CSV with RLE annotations\n",
    "csv_path = Path(\"severstal_dataset/train.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Prepare for decoding\n",
    "df[['ImageId', 'ClassId']] = df['ImageId_ClassId'].str.split('_', expand=True)\n",
    "df = df.dropna(subset=['EncodedPixels'])\n",
    "\n",
    "def rle_decode(mask_rle, shape=(1600, 256)):\n",
    "    s = list(map(int, mask_rle.split()))\n",
    "    starts, lengths = s[::2], s[1::2]\n",
    "    starts = np.array(starts) - 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape((shape[1], shape[0])).T  # reshape and transpose\n",
    "\n",
    "def show_image_with_masks(image_id, base_path):\n",
    "    image_path = base_path / \"train_images\" / image_id\n",
    "    image = np.array(Image.open(image_path))\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    for class_id in range(1, 5):\n",
    "        rle = df.loc[(df['ImageId'] == image_id) & (df['ClassId'] == str(class_id)), 'EncodedPixels']\n",
    "        if not rle.empty:\n",
    "            decoded_mask = rle_decode(rle.values[0])\n",
    "            mask[decoded_mask == 1] = class_id * 50  # shade for visual difference\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Original: {image_id}\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(mask, alpha=0.5, cmap='jet')\n",
    "    plt.title(\"With Defect Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Show a few random samples\n",
    "sample_ids = df['ImageId'].drop_duplicates().sample(3, random_state=42)\n",
    "for img_id in sample_ids:\n",
    "    show_image_with_masks(img_id, Path(\"severstal_dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Convert RLE Masks to Bounding Boxes for YOLO\n",
    "\n",
    "This cell converts each RLE mask in `train.csv` into a bounding box and saves it in YOLO format:\n",
    "\n",
    "`class_id x_center y_center width height` (normalized coordinates)\n",
    "\n",
    "It creates one `.txt` file per image (like YOLOv5 expects), placed in a `labels_yolo/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reload and clean the dataframe\n",
    "df = pd.read_csv(\"severstal_dataset/train.csv\")\n",
    "df[['ImageId', 'ClassId']] = df['ImageId_ClassId'].str.split('_', expand=True)\n",
    "df = df.dropna(subset=['EncodedPixels'])\n",
    "\n",
    "# Utility to decode RLE and get bounding box\n",
    "def rle_to_bbox(rle, shape=(1600, 256)):\n",
    "    s = list(map(int, rle.split()))\n",
    "    starts, lengths = s[::2], s[1::2]\n",
    "    starts = np.array(starts) - 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    mask = img.reshape((shape[1], shape[0])).T\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "    if not rows.any() or not cols.any():\n",
    "        return None\n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "# Prepare output directory\n",
    "label_dir = Path(\"severstal_dataset/labels_yolo\")\n",
    "label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Generate YOLO label files\n",
    "for image_id, group in df.groupby('ImageId'):\n",
    "    label_lines = []\n",
    "    for _, row in group.iterrows():\n",
    "        bbox = rle_to_bbox(row['EncodedPixels'])\n",
    "        if bbox:\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            x_center = (x_min + x_max) / 2 / 1600\n",
    "            y_center = (y_min + y_max) / 2 / 256\n",
    "            width = (x_max - x_min) / 1600\n",
    "            height = (y_max - y_min) / 256\n",
    "            class_id = int(row['ClassId']) - 1  # YOLO expects 0-based class IDs\n",
    "            label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "    if label_lines:\n",
    "        with open(label_dir / (image_id.replace('.jpg', '.txt')), 'w') as f:\n",
    "            f.write('\\n'.join(label_lines))\n",
    "\n",
    "print(f\"Done. Saved {len(os.listdir(label_dir))} label files in {label_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Visualize YOLO Bounding Boxes\n",
    "\n",
    "This cell loads a random `.jpg` image from the training set and overlays the corresponding bounding boxes extracted from YOLO `.txt` labels.\n",
    "Useful for checking if the bounding boxes correctly map to defect regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "\n",
    "def draw_yolo_boxes(image_path, label_path, image_size=(1600, 256)):\n",
    "    image = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(\"No label file found.\")\n",
    "        return\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            cls, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            # convert to pixel coordinates\n",
    "            x = (x_center - width / 2) * image_size[0]\n",
    "            y = (y_center - height / 2) * image_size[1]\n",
    "            w = width * image_size[0]\n",
    "            h = height * image_size[1]\n",
    "            rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x, y - 5, f\"Class {int(cls)}\", color='yellow', fontsize=10, weight='bold')\n",
    "\n",
    "    ax.set_title(f\"YOLO Bounding Boxes: {os.path.basename(image_path)}\")\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Sample one image from the labels directory\n",
    "label_dir = Path(\"severstal_dataset/labels_yolo\")\n",
    "image_dir = Path(\"severstal_dataset/train_images\")\n",
    "sample_txt = random.choice(list(label_dir.glob(\"*.txt\")))\n",
    "sample_img = image_dir / sample_txt.name.replace(\".txt\", \".jpg\")\n",
    "\n",
    "draw_yolo_boxes(sample_img, sample_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Prepare Dataset for YOLO TrainingThis section prepares the Severstal SEM dataset in the folder structure required by YOLOv8.It splits the dataset into training and validation sets, organizes images and labels, and generates a `data.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"severstal_yolo\")\n",
    "image_src = Path(\"severstal_dataset/train_images\")\n",
    "label_src = Path(\"severstal_dataset/labels_yolo\")\n",
    "\n",
    "for subset in ['train', 'val']:\n",
    "    (base_dir / f\"images/{subset}\").mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / f\"labels/{subset}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_files = [f.stem for f in label_src.glob(\"*.txt\")]\n",
    "random.seed(42)\n",
    "random.shuffle(all_files)\n",
    "split_index = int(0.8 * len(all_files))\n",
    "train_files = all_files[:split_index]\n",
    "val_files = all_files[split_index:]\n",
    "\n",
    "def move_files(file_list, subset):\n",
    "    for stem in file_list:\n",
    "        shutil.copy(image_src / f\"{stem}.jpg\", base_dir / f\"images/{subset}\" / f\"{stem}.jpg\")\n",
    "        shutil.copy(label_src / f\"{stem}.txt\", base_dir / f\"labels/{subset}\" / f\"{stem}.txt\")\n",
    "\n",
    "move_files(train_files, \"train\")\n",
    "move_files(val_files, \"val\")\n",
    "print(f\"Moved {len(train_files)} train and {len(val_files)} val images/labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Generate `data.yaml` fileThis YAML file tells YOLOv8 where to find training/validation data and how many classes are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = base_dir / \"data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "path: severstal_yolo\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 4\n",
    "names: [\"defect1\", \"defect2\", \"defect3\", \"defect4\"]\n",
    "\"\"\")\n",
    "print(f\"Created {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Train YOLOv8 on the Severstal DatasetNow that the data is ready, we can start training a YOLOv8 model using the Ultralytics library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics  # Uncomment if not already installed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # Replace with yolov8s.pt for better accuracy\n",
    "model.train(data=str(yaml_path), epochs=30, imgsz=640, batch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Visualize YOLOv8 Predictions on Validation ImagesThis cell runs inference using the trained YOLOv8 model and shows bounding box predictions over validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the best trained model (from previous run)\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Pick a few random validation images\n",
    "val_images = list(Path(\"severstal_yolo/images/val\").glob(\"*.jpg\"))\n",
    "sample_paths = random.sample(val_images, 3)\n",
    "\n",
    "for img_path in sample_paths:\n",
    "    results = model.predict(source=str(img_path), save=False, conf=0.25)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    image = cv2.imread(str(img_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = box.conf[0].item()\n",
    "        label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "        cv2.putText(image, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predictions on: {img_path.name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
